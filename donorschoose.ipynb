{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-22372c6645bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mWiSARD\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWiSARD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mWisard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWisard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/site-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_eng_float_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m from pandas.core.index import (Index, CategoricalIndex, Int64Index,\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m                                CategoricalIndex, _ensure_index)\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_shared_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m                                    \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                    create_block_manager_from_blocks)\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Series'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/site-packages/pandas/plotting/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                    \u001b[0mparallel_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlag_plot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                    autocorrelation_plot)\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboxplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_style\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_converter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/site-packages/pandas/plotting/_converter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFormatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLocator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/site-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m from dateutil.rrule import (rrule, MO, TU, WE, TH, FR, SA, SU, YEARLY,\n\u001b[0m\u001b[1;32m    153\u001b[0m                             \u001b[0mMONTHLY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEEKLY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDAILY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHOURLY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMINUTELY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                             SECONDLY)\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python35/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from WiSARD import WiSARD\n",
    "from Wisard import Wisard\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import *\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_file_path = 'train.csv'\n",
    "test_file_path = 'test.csv'\n",
    "resources_file_path = 'resources.csv'\n",
    "\n",
    "# Read data and store in DataFrame\n",
    "train_data = pd.read_csv(train_file_path, sep=',')\n",
    "#test_data = pd.read_csv(test_file_path, sep=',')\n",
    "resources_data = pd.read_csv(resources_file_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# splitting the training dataset int training (~80%) and test (~20%), because the official test dataset\n",
    "# doesn't have the the entries' classification, requiring validation with Kaggle's website\n",
    "\n",
    "#msk = np.random.rand(len(train_data)) < 0.8\n",
    "#train = train_data[msk]\n",
    "#test_data = train_data[~msk]\n",
    "#train_data = train\n",
    "\n",
    "print(train_data[\"project_is_approved\"].sum())\n",
    "print(\"Percent aproved: \", float(train_data[\"project_is_approved\"].sum()) / float(len(train_data)), \"\\n\")\n",
    "#print(train_data.groupby('project_subject_categories')['project_subject_categories'].nunique())\n",
    "\n",
    "train = train_data.sample(frac=0.8,random_state=200)\n",
    "test_data = train_data.drop(train.index)\n",
    "\n",
    "train_data = train\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessing part is partialy based on the following \"kernel\" on Kaggle:\n",
    "# https://www.kaggle.com/jgoldberg/donorschoose-eda-text-classification/notebook\n",
    "\n",
    "def preprocess(training_dataframe, resources_dataframe):\n",
    "    print(training_dataframe.shape)\n",
    "    print(resources_dataframe.shape)\n",
    "    \n",
    "    #\n",
    "    total_price = resources_dataframe.quantity * resources_dataframe.price\n",
    "    resources_dataframe[\"total_price\"] = total_price\n",
    "    \n",
    "    # dropping irrelevant columns\n",
    "    resources_dataframe = resources_dataframe.drop([\"description\", \"price\"], axis=1)\n",
    "    training_dataframe = training_dataframe.drop([\"teacher_id\"], axis=1)\n",
    "    \n",
    "    # grouping resources data by id\n",
    "    grouped_resources_dataframe = resources_dataframe.groupby(\"id\", as_index=False, sort=False).sum()\n",
    "    grouped_resources_dataframe\n",
    "    \n",
    "    # merging the two dataframes\n",
    "    cleaned_df = pd.merge(training_dataframe, grouped_resources_dataframe, how=\"inner\", on=[\"id\"])\n",
    "    \n",
    "    # splitting project categories\n",
    "    \n",
    "    cleaned_df[['category_1','category_2', \"category_3\"]] = cleaned_df['project_subject_categories'].str.split(', ', 3, expand=True)\n",
    "    \n",
    "    #cleaned_df[\"category_1\"] = cleaned_df[\"category_1\"].fillna(\"Not Informed\")\n",
    "    cleaned_df[\"category_2\"] = cleaned_df[\"category_2\"].fillna(\"Not Informed\")\n",
    "    \n",
    "    cleaned_df[\"total_price_category\"] = pd.cut(\n",
    "        cleaned_df[\"total_price\"], \n",
    "        bins=[0,100,250,500,1000,16000], \n",
    "        labels=[\"0-100\",\"101-250\",\"251-500\",\"501-1000\",\">1000\"]\n",
    "    )\n",
    "    \n",
    "    cleaned_df[\"n_previous_projects\"] = pd.cut(\n",
    "        cleaned_df[\"teacher_number_of_previously_posted_projects\"],\n",
    "        bins=[-1,1,5,10,25,50,500],\n",
    "        labels=['0-1','2-5','6-10','11-25','26-50','51+']\n",
    "    )\n",
    "    \n",
    "    cleaned_df[\"project_submitted_datetime\"] = pd.to_datetime(cleaned_df['project_submitted_datetime'])\n",
    "    cleaned_df[\"month\"] = cleaned_df['project_submitted_datetime'].dt.month\n",
    "    cleaned_df[\"quarter\"] = cleaned_df['project_submitted_datetime'].dt.quarter\n",
    "    \n",
    "    cleaned_df[\"teacher_prefix\"] = cleaned_df[\"teacher_prefix\"].fillna(\"unknown\")\n",
    "    \n",
    "    cleaned_df[\"project_essay_1\"] = cleaned_df[\"project_essay_1\"].fillna(\"\")\n",
    "    cleaned_df[\"project_essay_2\"] = cleaned_df[\"project_essay_2\"].fillna(\"\")\n",
    "    cleaned_df[\"project_essay_3\"] = cleaned_df[\"project_essay_3\"].fillna(\"\")\n",
    "    cleaned_df[\"project_essay_4\"] = cleaned_df[\"project_essay_4\"].fillna(\"\")\n",
    "    \n",
    "    #cleaned_df[\"merged_essays\"] = cleaned_df['project_title'].astype(str) + \" \" + cleaned_df['project_essay_1'].astype(str) + \" \" + cleaned_df['project_essay_2'].astype(str) + \" \" + cleaned_df['project_essay_3'].astype(str) + \" \" + cleaned_df['project_essay_4'].astype(str)\n",
    "    cleaned_df[\"merged_essays\"] = cleaned_df['project_essay_1'].astype(str) + \" \" + cleaned_df['project_essay_2'].astype(str) + \" \" + cleaned_df['project_essay_3'].astype(str) + \" \" + cleaned_df['project_essay_4'].astype(str)\n",
    "    \n",
    "    # dropping more columns\n",
    "    cleaned_df = cleaned_df.drop([\n",
    "        \"project_submitted_datetime\", \n",
    "        \"project_essay_1\", \n",
    "        \"project_essay_2\", \n",
    "        \"project_essay_3\", \n",
    "        \"project_essay_4\",\n",
    "        \"quantity\",\n",
    "        \"total_price\",\n",
    "        \"teacher_number_of_previously_posted_projects\"], \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# returns a list with the following format\n",
    "# [\n",
    "#     [\"001101...010101\", 1]\n",
    "#     [\"001111...000001\", 1]\n",
    "#     [\"101001...111100\", 0]\n",
    "# ]\n",
    "def convert_to_bits_string(dataframe):\n",
    "    print(dataframe.shape)\n",
    "    \n",
    "    project_grade_category_mapping = {\n",
    "        'Grades PreK-2':\"00000000000000000000000000000000000000000000000000\", \n",
    "        'Grades 3-5':\"10000000000000000000000000000000000000000000000000\", \n",
    "        'Grades 6-8':\"11000000000000000000000000000000000000000000000000\", \n",
    "        'Grades 9-12':\"11100000000000000000000000000000000000000000000000\"\n",
    "    }\n",
    "\n",
    "    teacher_prefix_mapping = {\n",
    "        'Ms.':\"11110000000000000000000000000000000000000000000000\", \n",
    "        'Mrs.':\"11111000000000000000000000000000000000000000000000\", \n",
    "        'Mr.':\"11111100000000000000000000000000000000000000000000\", \n",
    "        'Teacher':\"11111110000000000000000000000000000000000000000000\", \n",
    "        'Dr.':\"11111111000000000000000000000000000000000000000000\", \n",
    "        'unknown':\"11111111100000000000000000000000000000000000000000\"\n",
    "    }\n",
    "\n",
    "    n_previous_projects_mapping = {\n",
    "        '0-1':\"11111111110000000000000000000000000000000000000000\",\n",
    "        '2-5':\"11111111111000000000000000000000000000000000000000\",\n",
    "        '6-10':\"11111111111100000000000000000000000000000000000000\",\n",
    "        '11-25':\"11111111111110000000000000000000000000000000000000\",\n",
    "        '26-50':\"11111111111111000000000000000000000000000000000000\",\n",
    "        '51+':\"11111111111111100000000000000000000000000000000000\"\n",
    "    }\n",
    "\n",
    "    total_price_category_mapping = {\n",
    "        \"0-100\":\"11111111111111110000000000000000000000000000000000\",\n",
    "        \"101-250\":\"11111111111111111000000000000000000000000000000000\",\n",
    "        \"251-500\":\"11111111111111111100000000000000000000000000000000\",\n",
    "        \"501-1000\":\"11111111111111111110000000000000000000000000000000\",\n",
    "        \">1000\":\"11111111111111111111000000000000000000000000000000\"\n",
    "    }\n",
    "    \n",
    "    month_mapping = {\n",
    "        \"1\":\"11111111111111111111100000000000000000000000000000\",\n",
    "        \"2\":\"11111111111111111111110000000000000000000000000000\",\n",
    "        \"3\":\"11111111111111111111111000000000000000000000000000\",\n",
    "        \"4\":\"11111111111111111111111100000000000000000000000000\",\n",
    "        \"5\":\"11111111111111111111111110000000000000000000000000\",\n",
    "        \"6\":\"11111111111111111111111111000000000000000000000000\",\n",
    "        \"7\":\"11111111111111111111111111100000000000000000000000\",\n",
    "        \"8\":\"11111111111111111111111111110000000000000000000000\",\n",
    "        \"9\":\"11111111111111111111111111111000000000000000000000\",\n",
    "        \"10\":\"11111111111111111111111111111100000000000000000000\",\n",
    "        \"11\":\"11111111111111111111111111111110000000000000000000\",\n",
    "        \"12\":\"11111111111111111111111111111111000000000000000000\"\n",
    "    }\n",
    "    \n",
    "    quarter_mapping = {\n",
    "        \"1\":\"11111111111111111111111111111111100000000000000000\",\n",
    "        \"2\":\"11111111111111111111111111111111110000000000000000\",\n",
    "        \"3\":\"11111111111111111111111111111111111000000000000000\",\n",
    "        \"4\":\"11111111111111111111111111111111111111111111100000\"\n",
    "    }\n",
    "    \n",
    "    category_mapping = {\n",
    "        \"Not Informed\":\"11111111111111111111111111111111111100000000000000\",\n",
    "        \"Applied Learning\":\"11111111111111111111111111111111111110000000000000\",\n",
    "        \"Health & Sports\":\"11111111111111111111111111111111111111000000000000\",\n",
    "        \"History & Civics\":\"11111111111111111111111111111111111111100000000000\",\n",
    "        \"Literacy & Language\":\"11111111111111111111111111111111111111110000000000\",\n",
    "        \"Math & Science\":\"11111111111111111111111111111111111111111000000000\",\n",
    "        \"Music & The Arts\":\"11111111111111111111111111111111111111111100000000\",\n",
    "        \"Special Needs\":\"11111111111111111111111111111111111111111110000000\",\n",
    "        \"Warmth\":\"11111111111111111111111111111111111111111111000000\",\n",
    "        \"Care & Hunger\":\"11111111111111111111111111111111111111111111000000\", # Equals to warmth, because they are the same thing\n",
    "    }\n",
    "    \n",
    "    combined_input_and_expected_output = []\n",
    "    input_list = []\n",
    "    expected_output_list = []\n",
    "    \n",
    "    n = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        #print(row)\n",
    "        #if n >= 10:\n",
    "        #    break\n",
    "        #n = n + 1\n",
    "        \n",
    "        bits_string = \"\"\n",
    "        bits_string = project_grade_category_mapping[row[\"project_grade_category\"]]\n",
    "        bits_string = bits_string + teacher_prefix_mapping[row[\"teacher_prefix\"]]\n",
    "        bits_string = bits_string + n_previous_projects_mapping[row[\"n_previous_projects\"]]\n",
    "        bits_string = bits_string + total_price_category_mapping[row[\"total_price_category\"]]\n",
    "        \n",
    "        bits_string = bits_string + month_mapping[str(row[\"month\"])]\n",
    "        bits_string = bits_string + quarter_mapping[str(row[\"quarter\"])]\n",
    "        bits_string = bits_string + category_mapping[row[\"category_1\"]]\n",
    "        bits_string = bits_string + category_mapping[row[\"category_2\"]]\n",
    "        \n",
    "        bit_int_list = [int(c) for c in bits_string]\n",
    "        expected_output = str(row[\"project_is_approved\"])\n",
    "        \n",
    "        input_list.append(bit_int_list)\n",
    "        expected_output_list.append(expected_output)\n",
    "        \n",
    "        combined_input_and_expected_output.append([bit_int_list, expected_output])\n",
    "        \n",
    "    return input_list, expected_output_list, combined_input_and_expected_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = preprocess(train_data, resources_data)\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = preprocess(test_data, resources_data)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_df[\"category_1\"].unique())\n",
    "print(training_df[\"category_2\"].unique())\n",
    "print(training_df[\"category_3\"].unique())\n",
    "print(test_df[\"category_1\"].unique())\n",
    "print(test_df[\"category_2\"].unique())\n",
    "print(test_df[\"category_3\"].unique())\n",
    "\n",
    "print(test_df[\"month\"].unique())\n",
    "print(test_df[\"quarter\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-z]+')\n",
    "test_df[\"words_list\"] = None\n",
    "#training_df[\"words_list\"] = training_df[\"words_list\"].astype([])\n",
    "words_universe_set = set()\n",
    "count = 0\n",
    "\n",
    "for row in test_df.index:\n",
    "    text = test_df.loc[row, \"merged_essays\"]\n",
    "    words_list = [word for word in tokenizer.tokenize(text.lower()) if word not in stopwords.words('english')]\n",
    "    \n",
    "    words_universe_set.update(words_list)\n",
    "    test_df.loc[row , \"words_list\"] = json.dumps(words_list)\n",
    "    #print(words_list)\n",
    "    #print(words_universe_set)\n",
    "    count = count + 1\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "        print(len(words_universe_set), \"\\n\")\n",
    "        #break\n",
    "        \n",
    "print(len(words_universe_set))\n",
    "#print(words_universe_set)\n",
    "#print(test_df[\"words_list\"][:10])\n",
    "\n",
    "#print(test_df[\"words_list\"][:1])\n",
    "#print(json.loads((test_df[\"words_list\"][1])))\n",
    "#a_list = json.loads(test_df[\"words_list\"][1])\n",
    "#print(\"\\n\\n\\n\", a_list)\n",
    "#print(\"\\n\\n\\n\", a_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "#syns = wordnet.synsets(\"program\")\n",
    "#print(syns[0].lemmas()[0].name())\n",
    "#print(syns)\n",
    "\n",
    "#syns = wordnet.synsets(\"plan\")\n",
    "#print(syns[0].lemmas()[0].name())\n",
    "#print(syns)\n",
    "\n",
    "syngroups = set()\n",
    "unrecognized = 0\n",
    "\n",
    "for word in words_universe_set:\n",
    "    syns = wordnet.synsets(word)\n",
    "    #print(word, syns)\n",
    "    if len(syns) > 0:\n",
    "        syngroups.add(wordnet.synsets(word)[0].lemmas()[0].name())\n",
    "    else:\n",
    "        unrecognized = unrecognized + 1\n",
    "\n",
    "print(len(syngroups))\n",
    "print(unrecognized)\n",
    "#print(syngroups)\n",
    "\n",
    "syngroups_level_2 = set()\n",
    "unrecognized = 0\n",
    "\n",
    "for word in syngroups:\n",
    "    syns = wordnet.synsets(word)\n",
    "    #print(word, syns)\n",
    "    if len(syns) > 0:\n",
    "        syngroups_level_2.add(wordnet.synsets(word)[0].lemmas()[0].name())\n",
    "    else:\n",
    "        unrecognized = unrecognized + 1\n",
    "        \n",
    "print(len(syngroups))\n",
    "print(unrecognized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synsets(\"sus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input, expected_output, training_combined = convert_to_bits_string(training_df)\n",
    "test_input, test_expected_output, test_combined = convert_to_bits_string(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_input))\n",
    "print(len(expected_output))\n",
    "\n",
    "print(len(test_input))\n",
    "print(len(test_expected_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get Firmino's implementation to return different to everything 1,\n",
    "# I had to train only on them first 100 observations, set the tupple \n",
    "# size to 50 or more and the bleaching to True.\n",
    "#w = WiSARD(num_bits_addr = 50, bleaching = True)\n",
    "\n",
    "#a_training_input = training_input[:100]\n",
    "#a_expected_output = expected_output[:100]\n",
    "\n",
    "#w.fit(a_training_input, a_expected_output)\n",
    "\n",
    "# Using personal Wisard implementation\n",
    "\n",
    "wann = Wisard(50, 3546)\n",
    "wann.train(training_input, expected_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eo = np.sum(expected_output)\n",
    "\n",
    "#print(expected_output[0:100])\n",
    "\n",
    "# In-sample performance\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluates Guilherme's wisard implementation\n",
    "#def evaluate_performance(test_data_combined):\n",
    "#    correct_predictions = 0\n",
    "#    for combined in test_data_combined:\n",
    "#        prediction = wann.predict(combined[0])\n",
    "#        #print(prediction)\n",
    "#        prediction = prediction[\"class\"]\n",
    "#        expected = combined[1]\n",
    "#        #print(prediction, expected)\n",
    "#        if prediction == expected:\n",
    "#            #print(\"Correct!\")\n",
    "#            correct_predictions = correct_predictions + 1\n",
    "#    print(correct_predictions)\n",
    "#    return correct_predictions\n",
    "\n",
    "def evaluate_performance(test_data_combined):\n",
    "    #print(\"Number of observations: \", test_data_combined)\n",
    "    correct_predictions = 0\n",
    "    wrong_predictions = 0\n",
    "    zeros_predicted = 0\n",
    "    ones_predicted = 0\n",
    "    zeros_correct = 0\n",
    "    ones_correct = 0\n",
    "    zeros_wrong = 0\n",
    "    ones_wrong = 0\n",
    "    for combined in test_data_combined:\n",
    "        prediction = wann.predict(combined[0])\n",
    "        prediction = prediction[\"class\"]\n",
    "        \n",
    "        if prediction == \"0\":\n",
    "            #print(\"Prediction: \", prediction[0], combined)\n",
    "            zeros_predicted = zeros_predicted + 1\n",
    "        elif prediction == \"1\":\n",
    "            ones_predicted = ones_predicted + 1\n",
    "        #print(prediction)\n",
    "        expected = combined[1]\n",
    "        #print(prediction, expected)\n",
    "        if prediction == expected:\n",
    "            #print(\"Correct!\")\n",
    "            correct_predictions = correct_predictions + 1\n",
    "            \n",
    "            if prediction == \"0\":\n",
    "                zeros_correct = zeros_correct + 1\n",
    "            elif prediction == \"1\":\n",
    "                ones_correct = ones_correct + 1\n",
    "        else:\n",
    "            wrong_predictions = wrong_predictions + 1\n",
    "            \n",
    "            if prediction == \"0\":\n",
    "                zeros_wrong = zeros_wrong + 1\n",
    "            elif prediction == \"1\":\n",
    "                ones_wrong = ones_wrong + 1\n",
    "    \n",
    "    print(\"Number of observations: \", len(test_data_combined))\n",
    "    print(\"Predicted correctly: \", correct_predictions)\n",
    "    print(\"Predicted wrongly: \", wrong_predictions)\n",
    "    print(\"Predicted zeros: \", zeros_predicted)\n",
    "    print(\"Predicted ones: \", ones_predicted)\n",
    "    print(\"Zeros correct: \", zeros_correct)\n",
    "    print(\"Ones correct: \", ones_correct)\n",
    "    print(\"Zeros wrong: \", zeros_wrong)\n",
    "    print(\"Ones Wrong: \", ones_wrong)\n",
    "    return correct_predictions\n",
    "\n",
    "#Evaluates Firminos's wisard implementation\n",
    "def evaluate_performance2(test_data_combined):\n",
    "    #print(\"Number of observations: \", test_data_combined)\n",
    "    correct_predictions = 0\n",
    "    wrong_predictions = 0\n",
    "    zeros_predicted = 0\n",
    "    ones_predicted = 0\n",
    "    zeros_correct = 0\n",
    "    ones_correct = 0\n",
    "    zeros_wrong = 0\n",
    "    ones_wrong = 0\n",
    "    for combined in test_data_combined:\n",
    "        prediction = w.predict([combined[0]])\n",
    "        if prediction[0] == \"0\":\n",
    "            #print(\"Prediction: \", prediction[0], combined)\n",
    "            zeros_predicted = zeros_predicted + 1\n",
    "        elif prediction[0] == \"1\":\n",
    "            ones_predicted = ones_predicted + 1\n",
    "        #print(prediction)\n",
    "        expected = combined[1]\n",
    "        #print(prediction, expected)\n",
    "        if prediction[0] == expected:\n",
    "            #print(\"Correct!\")\n",
    "            correct_predictions = correct_predictions + 1\n",
    "            \n",
    "            if prediction[0] == \"0\":\n",
    "                zeros_correct = zeros_correct + 1\n",
    "            elif prediction[0] == \"1\":\n",
    "                ones_correct = ones_correct + 1\n",
    "        else:\n",
    "            wrong_predictions = wrong_predictions + 1\n",
    "            \n",
    "            if prediction[0] == \"0\":\n",
    "                zeros_wrong = zeros_wrong + 1\n",
    "            elif prediction[0] == \"1\":\n",
    "                ones_wrong = ones_wrong + 1\n",
    "    \n",
    "    print(\"Number of observations: \", len(test_data_combined))\n",
    "    print(\"Predicted correctly: \", correct_predictions)\n",
    "    print(\"Predicted wrongly: \", wrong_predictions)\n",
    "    print(\"Predicted zeros: \", zeros_predicted)\n",
    "    print(\"Predicted ones: \", ones_predicted)\n",
    "    print(\"Zeros correct: \", zeros_correct)\n",
    "    print(\"Ones correct: \", ones_correct)\n",
    "    print(\"Zeros wrong: \", zeros_wrong)\n",
    "    print(\"Ones Wrong: \", ones_wrong)\n",
    "    return correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First results, used as reference for improvement:\n",
    "# In-sample performance:  0.711748840665465\n",
    "# Expected out-sample performance:  0.585333986607872\n",
    "\n",
    "# Evaluates Guilherme's wisard implementation\n",
    "#print(\"In-sample performance: \", evaluate_performance(training_combined[:5]) / len(training_combined[:5]))\n",
    "#print(\"Expected out-sample performance: \", evaluate_performance(test_combined[:5]) / len(test_combined[:5]))\n",
    "#print(\"In-sample performance: \", evaluate_performance(training_combined) / len(training_combined))\n",
    "#print(\"Expected out-sample performance: \", evaluate_performance(test_combined) / len(test_combined))\n",
    "\n",
    "print(\"In-sample performance: \", float(evaluate_performance(training_combined)) / float(len(training_combined)))\n",
    "print(\"Ones distribution: \", float(train_data[\"project_is_approved\"].sum()) / float(len(train_data[\"project_is_approved\"])))\n",
    "print(\"Ones: \", train_data[\"project_is_approved\"].sum(), \"Zeros: \", train_data[\"project_is_approved\"].sum() - len(train_data[\"project_is_approved\"]))\n",
    "print(\"\\n\")\n",
    "print(\"Expected out-sample performance: \", float(evaluate_performance(test_combined)) / float(len(test_combined)))\n",
    "print(\"Ones distribution: \", float(test_data[\"project_is_approved\"].sum()) / float(len(test_data[\"project_is_approved\"])))\n",
    "print(\"Ones: \", test_data[\"project_is_approved\"].sum(), \"Zeros: \", (test_data[\"project_is_approved\"].sum() - len(test_data[\"project_is_approved\"])))\n",
    "\n",
    "\n",
    "# Evaluates Firmino's wisard implementation\n",
    "#print(\"In-sample performance: \", float(evaluate_performance2(training_combined)) / float(len(training_combined)))\n",
    "#print(\"Ones distribution: \", float(train_data[\"project_is_approved\"].sum()) / float(len(train_data[\"project_is_approved\"])))\n",
    "#print(\"Ones: \", train_data[\"project_is_approved\"].sum(), \"Zeros: \", train_data[\"project_is_approved\"].sum() - len(train_data[\"project_is_approved\"]))\n",
    "#print(\"\\n\")\n",
    "#print(\"Expected out-sample performance: \", float(evaluate_performance2(test_combined)) / float(len(test_combined)))\n",
    "#print(\"Ones distribution: \", float(test_data[\"project_is_approved\"].sum()) / float(len(test_data[\"project_is_approved\"])))\n",
    "#print(\"Ones: \", test_data[\"project_is_approved\"].sum(), \"Zeros: \", (test_data[\"project_is_approved\"].sum() - len(test_data[\"project_is_approved\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for discriminator in wann.discriminators:\n",
    "    print(discriminator.input_class)\n",
    "    print(discriminator.input_length)\n",
    "    print(discriminator.tupple_size)\n",
    "    print(discriminator.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
