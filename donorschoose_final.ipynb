{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from Wisard import Wisard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessing part is partialy based on the following \"kernel\" on Kaggle:\n",
    "# https://www.kaggle.com/jgoldberg/donorschoose-eda-text-classification/notebook\n",
    "\n",
    "def preprocess(training_dataframe, resources_dataframe):\n",
    "    #print(training_dataframe.shape)\n",
    "    #print(resources_dataframe.shape)\n",
    "    \n",
    "    #\n",
    "    total_price = resources_dataframe.quantity * resources_dataframe.price\n",
    "    resources_dataframe[\"total_price\"] = total_price\n",
    "    \n",
    "    # dropping irrelevant columns\n",
    "    resources_dataframe = resources_dataframe.drop([\"description\", \"price\"], axis=1)\n",
    "    training_dataframe = training_dataframe.drop([\"teacher_id\"], axis=1)\n",
    "    \n",
    "    # grouping resources data by id\n",
    "    grouped_resources_dataframe = resources_dataframe.groupby(\"id\", as_index=False, sort=False).sum()\n",
    "    grouped_resources_dataframe\n",
    "    \n",
    "    # merging the two dataframes\n",
    "    cleaned_df = pd.merge(training_dataframe, grouped_resources_dataframe, how=\"inner\", on=[\"id\"])\n",
    "    \n",
    "    # splitting project categories\n",
    "    \n",
    "    cleaned_df[['category_1','category_2']] = cleaned_df['project_subject_categories'].str.replace(\", Care & Hunger\", \"\").str.split(', ', 3, expand=True)\n",
    "    #print(cleaned_df['project_subject_categories'].str.replace(\", Care & Hunger\", \"\").str.split(', ', 3, expand=True))\n",
    "    \n",
    "    cleaned_df[['subcategory_1','subcategory_2']] = cleaned_df['project_subject_subcategories'].str.replace(\", Care & Hunger\", \"\").str.split(', ', 3, expand=True)\n",
    "    \n",
    "    #cleaned_df[\"category_1\"] = cleaned_df[\"category_1\"].fillna(\"Not Informed\")\n",
    "    cleaned_df[\"category_2\"] = cleaned_df[\"category_2\"].fillna(\"Not Informed\")\n",
    "    cleaned_df[\"subcategory_2\"] = cleaned_df[\"subcategory_2\"].fillna(\"Not Informed\")\n",
    "    \n",
    "    cleaned_df[\"total_price_category\"] = pd.cut(\n",
    "        cleaned_df[\"total_price\"], \n",
    "        bins=[0,100,250,500,1000,16000], \n",
    "        labels=[\"0-100\",\"101-250\",\"251-500\",\"501-1000\",\">1000\"]\n",
    "    )\n",
    "    \n",
    "    cleaned_df[\"n_previous_projects\"] = pd.cut(\n",
    "        cleaned_df[\"teacher_number_of_previously_posted_projects\"],\n",
    "        bins=[-1,1,5,10,25,50,500],\n",
    "        labels=['0-1','2-5','6-10','11-25','26-50','51+']\n",
    "    )\n",
    "    \n",
    "    cleaned_df[\"project_submitted_datetime\"] = pd.to_datetime(cleaned_df['project_submitted_datetime'])\n",
    "    cleaned_df[\"month\"] = cleaned_df['project_submitted_datetime'].dt.month\n",
    "    cleaned_df[\"quarter\"] = cleaned_df['project_submitted_datetime'].dt.quarter\n",
    "    \n",
    "    cleaned_df[\"teacher_prefix\"] = cleaned_df[\"teacher_prefix\"].fillna(\"unknown\")\n",
    "    \n",
    "    cleaned_df[\"project_essay_1\"] = cleaned_df[\"project_essay_1\"].fillna(\"\")\n",
    "    cleaned_df[\"project_essay_2\"] = cleaned_df[\"project_essay_2\"].fillna(\"\")\n",
    "    cleaned_df[\"project_essay_3\"] = cleaned_df[\"project_essay_3\"].fillna(\"\")\n",
    "    cleaned_df[\"project_essay_4\"] = cleaned_df[\"project_essay_4\"].fillna(\"\")\n",
    "    \n",
    "    #cleaned_df[\"merged_essays\"] = cleaned_df['project_title'].astype(str) + \" \" + cleaned_df['project_essay_1'].astype(str) + \" \" + cleaned_df['project_essay_2'].astype(str) + \" \" + cleaned_df['project_essay_3'].astype(str) + \" \" + cleaned_df['project_essay_4'].astype(str)\n",
    "    cleaned_df[\"merged_essays\"] = cleaned_df['project_essay_1'].astype(str) + \" \" + cleaned_df['project_essay_2'].astype(str) + \" \" + cleaned_df['project_essay_3'].astype(str) + \" \" + cleaned_df['project_essay_4'].astype(str)\n",
    "    \n",
    "    # dropping more columns\n",
    "    cleaned_df = cleaned_df.drop([\n",
    "        \"project_submitted_datetime\", \n",
    "        \"project_essay_1\", \n",
    "        \"project_essay_2\", \n",
    "        \"project_essay_3\", \n",
    "        \"project_essay_4\",\n",
    "        \"quantity\",\n",
    "        \"total_price\",\n",
    "        \"teacher_number_of_previously_posted_projects\"], \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# returns a list with the following format\n",
    "# [\n",
    "#     [\"001101...010101\", 1]\n",
    "#     [\"001111...000001\", 1]\n",
    "#     [\"101001...111100\", 0]\n",
    "# ]\n",
    "def convert_to_bits_string(dataframe):\n",
    "    print(\"Converting dataframe of shape \", dataframe.shape, \" to a list of binary values.\")\n",
    "    \n",
    "    project_grade_category_mapping = { # 4\n",
    "        'Grades PreK-2':  \"1000\", \n",
    "        'Grades 3-5':     \"0100\", \n",
    "        'Grades 6-8':     \"0010\", \n",
    "        'Grades 9-12':    \"0001\"\n",
    "    }\n",
    "\n",
    "    teacher_prefix_mapping = { # 6\n",
    "        'Ms.':     \"100000\", \n",
    "        'Mrs.':    \"010000\", \n",
    "        'Mr.':     \"001000\", \n",
    "        'Teacher': \"000100\", \n",
    "        'Dr.':     \"000010\", \n",
    "        'unknown': \"000001\"\n",
    "    }\n",
    "\n",
    "    n_previous_projects_mapping = { # 6\n",
    "        '0-1':     \"100000\",\n",
    "        '2-5':     \"010000\",\n",
    "        '6-10':    \"001000\",\n",
    "        '11-25':   \"000100\",\n",
    "        '26-50':   \"000010\",\n",
    "        '51+':     \"000001\"\n",
    "    }\n",
    "\n",
    "    total_price_category_mapping = { # 6\n",
    "        \"0-100\":     \"100000\",\n",
    "        \"101-250\":   \"010000\",\n",
    "        \"251-500\":   \"001000\",\n",
    "        \"501-1000\":  \"000100\",\n",
    "        \">1000\":     \"000010\"\n",
    "    }\n",
    "    \n",
    "    month_mapping = { # 12\n",
    "        \"1\":  \"100000000000\",\n",
    "        \"2\":  \"010000000000\",\n",
    "        \"3\":  \"001000000000\",\n",
    "        \"4\":  \"000100000000\",\n",
    "        \"5\":  \"000010000000\",\n",
    "        \"6\":  \"000001000000\",\n",
    "        \"7\":  \"000000100000\",\n",
    "        \"8\":  \"000000010000\",\n",
    "        \"9\":  \"000000001000\",\n",
    "        \"10\": \"000000000100\",\n",
    "        \"11\": \"000000000010\",\n",
    "        \"12\": \"000000000001\"\n",
    "    }\n",
    "    \n",
    "    quarter_mapping = { # 4\n",
    "        \"1\":\"1000\",\n",
    "        \"2\":\"0100\",\n",
    "        \"3\":\"0010\",\n",
    "        \"4\":\"0001\"\n",
    "    }\n",
    "    \n",
    "    category_mapping = { # 10\n",
    "        \"Not Informed\":          \"1000000000\",\n",
    "        \"Applied Learning\":      \"0100000000\",\n",
    "        \"Health & Sports\":       \"0010000000\",\n",
    "        \"History & Civics\":      \"0001000000\",\n",
    "        \"Literacy & Language\":   \"0000100000\",\n",
    "        \"Math & Science\":        \"0000010000\",\n",
    "        \"Music & The Arts\":      \"0000001000\",\n",
    "        \"Special Needs\":         \"0000000100\",\n",
    "        \"Warmth\":                \"0000000010\",\n",
    "        \"Care & Hunger\":         \"0000000010\", # Equals to warmth, because they are the same thing\n",
    "    }\n",
    "    \n",
    "    subcategory_mapping = { # 30\n",
    "        \"Not Informed\":          \"100000000000000000000000000000\",\n",
    "        \"Literacy\":              \"010000000000000000000000000000\",\n",
    "        \"Performing Arts\":       \"001000000000000000000000000000\",\n",
    "        \"Applied Sciences\":      \"000100000000000000000000000000\",\n",
    "        \"Health & Wellness\":     \"000010000000000000000000000000\",\n",
    "        \"Character Education\":   \"000001000000000000000000000000\",\n",
    "        \"Early Development\":     \"000000100000000000000000000000\",\n",
    "        \"Mathematics\":           \"000000010000000000000000000000\",\n",
    "        \"Literature & Writing\":  \"000000001000000000000000000000\",\n",
    "        \"Special Needs\":         \"000000000100000000000000000000\", \n",
    "        \"ESL\":                   \"000000000010000000000000000000\", \n",
    "        \"Health & Life Science\": \"000000000001000000000000000000\", \n",
    "        \"College & Career Prep\": \"000000000000100000000000000000\", \n",
    "        \"Environmental Science\": \"000000000000010000000000000000\", \n",
    "        \"Other\":                 \"000000000000001000000000000000\", \n",
    "        \"Music\":                 \"000000000000000100000000000000\", \n",
    "        \"Visual Arts\":           \"000000000000000010000000000000\", \n",
    "        \"History & Geography\":   \"000000000000000001000000000000\", \n",
    "        \"Gym & Fitness\":         \"000000000000000000100000000000\", \n",
    "        \"Warmth\":                \"000000000000000000010000000000\", \n",
    "        \"Extracurricular\":       \"000000000000000000001000000000\", \n",
    "        \"Team Sports\":           \"000000000000000000000100000000\", \n",
    "        \"Social Sciences\":       \"000000000000000000000010000000\", \n",
    "        \"Foreign Languages\":     \"000000000000000000000001000000\", \n",
    "        \"Parent Involvement\":    \"000000000000000000000000100000\", \n",
    "        \"Nutrition Education\":   \"000000000000000000000000010000\", \n",
    "        \"Community Service\":     \"000000000000000000000000001000\", \n",
    "        \"Financial Literacy\":    \"000000000000000000000000000100\", \n",
    "        \"Civics & Government\":   \"000000000000000000000000000010\", \n",
    "        \"Economics\":             \"000000000000000000000000000001\", \n",
    "        \n",
    "    }\n",
    "    \n",
    "    school_state_mapping = { # 50\n",
    "        'NV':\"10000000000000000000000000000000000000000000000000\", \n",
    "        'GA':\"01000000000000000000000000000000000000000000000000\", \n",
    "        'UT':\"00100000000000000000000000000000000000000000000000\", \n",
    "        'NC':\"00010000000000000000000000000000000000000000000000\", \n",
    "        'CA':\"00001000000000000000000000000000000000000000000000\", \n",
    "        'DE':\"00000100000000000000000000000000000000000000000000\", \n",
    "        'MO':\"00000010000000000000000000000000000000000000000000\", \n",
    "        'SC':\"00000001000000000000000000000000000000000000000000\", \n",
    "        'IN':\"00000000100000000000000000000000000000000000000000\", \n",
    "        'IL':\"00000000010000000000000000000000000000000000000000\", \n",
    "        'VA':\"00000000001000000000000000000000000000000000000000\",\n",
    "        'PA':\"00000000000100000000000000000000000000000000000000\", \n",
    "        'NY':\"00000000000010000000000000000000000000000000000000\", \n",
    "        'FL':\"00000000000001000000000000000000000000000000000000\", \n",
    "        'NJ':\"00000000000000100000000000000000000000000000000000\", \n",
    "        'TX':\"00000000000000010000000000000000000000000000000000\", \n",
    "        'LA':\"00000000000000001000000000000000000000000000000000\", \n",
    "        'ID':\"00000000000000000100000000000000000000000000000000\", \n",
    "        'OH':\"00000000000000000010000000000000000000000000000000\", \n",
    "        'OR':\"00000000000000000001000000000000000000000000000000\", \n",
    "        'MD':\"00000000000000000000100000000000000000000000000000\", \n",
    "        'WA':\"00000000000000000000010000000000000000000000000000\",\n",
    "        'MA':\"00000000000000000000001000000000000000000000000000\", \n",
    "        'KY':\"00000000000000000000000100000000000000000000000000\", \n",
    "        'AZ':\"00000000000000000000000010000000000000000000000000\", \n",
    "        'MI':\"00000000000000000000000001000000000000000000000000\", \n",
    "        'CT':\"00000000000000000000000000100000000000000000000000\", \n",
    "        'AR':\"00000000000000000000000000010000000000000000000000\", \n",
    "        'WV':\"00000000000000000000000000001000000000000000000000\", \n",
    "        'NM':\"00000000000000000000000000000100000000000000000000\", \n",
    "        'WI':\"00000000000000000000000000000010000000000000000000\", \n",
    "        'MN':\"00000000000000000000000000000001000000000000000000\", \n",
    "        'OK':\"00000000000000000000000000000000100000000000000000\",\n",
    "        'AL':\"00000000000000000000000000000000010000000000000000\", \n",
    "        'TN':\"00000000000000000000000000000000001000000000000000\", \n",
    "        'IA':\"00000000000000000000000000000000000100000000000000\", \n",
    "        'KS':\"00000000000000000000000000000000000010000000000000\", \n",
    "        'CO':\"00000000000000000000000000000000000001000000000000\", \n",
    "        'DC':\"00000000000000000000000000000000000000100000000000\", \n",
    "        'WY':\"00000000000000000000000000000000000000010000000000\", \n",
    "        'NH':\"00000000000000000000000000000000000000001000000000\", \n",
    "        'HI':\"00000000000000000000000000000000000000000100000000\", \n",
    "        'SD':\"00000000000000000000000000000000000000000010000000\", \n",
    "        'MT':\"00000000000000000000000000000000000000000001000000\",\n",
    "        'MS':\"00000000000000000000000000000000000000000000100000\", \n",
    "        'RI':\"00000000000000000000000000000000000000000000010000\", \n",
    "        'VT':\"00000000000000000000000000000000000000000000001000\", \n",
    "        'ME':\"00000000000000000000000000000000000000000000000100\", \n",
    "        'NE':\"00000000000000000000000000000000000000000000000010\", \n",
    "        'AK':\"00000000000000000000000000000000000000000000000001\", \n",
    "        'ND':\"00000000000000000000000000000000000000000000000000\"\n",
    "    }\n",
    "    \n",
    "    combined_input_and_expected_output = []\n",
    "    input_list = []\n",
    "    expected_output_list = []\n",
    "    \n",
    "    n = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        #print(row)\n",
    "        #if n >= 10:\n",
    "        #    break\n",
    "        #n = n + 1\n",
    "        \n",
    "        # total 128 bits\n",
    "        bits_string = \"\"\n",
    "        bits_string = project_grade_category_mapping[row[\"project_grade_category\"]]\n",
    "        bits_string = bits_string + teacher_prefix_mapping[row[\"teacher_prefix\"]]\n",
    "        bits_string = bits_string + n_previous_projects_mapping[row[\"n_previous_projects\"]]\n",
    "        bits_string = bits_string + total_price_category_mapping[row[\"total_price_category\"]]\n",
    "        \n",
    "        bits_string = bits_string + month_mapping[str(row[\"month\"])]\n",
    "        bits_string = bits_string + quarter_mapping[str(row[\"quarter\"])]\n",
    "        bits_string = bits_string + category_mapping[row[\"category_1\"]]\n",
    "        bits_string = bits_string + category_mapping[row[\"category_2\"]] # perhaps it is possible to ignore this one\n",
    "        \n",
    "        bits_string = bits_string + subcategory_mapping[row[\"subcategory_1\"]]\n",
    "        bits_string = bits_string + subcategory_mapping[row[\"subcategory_2\"]]\n",
    "        bits_string = bits_string + school_state_mapping[row[\"school_state\"]]\n",
    "        \n",
    "        bit_int_list = [int(c) for c in bits_string]\n",
    "        expected_output = str(row[\"project_is_approved\"])\n",
    "        \n",
    "        input_list.append(bit_int_list)\n",
    "        expected_output_list.append(expected_output)\n",
    "        \n",
    "        combined_input_and_expected_output.append([bit_int_list, expected_output])\n",
    "        \n",
    "    return input_list, expected_output_list, combined_input_and_expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    # load data\n",
    "    train_file_path = 'train.csv'\n",
    "    # Test data file not considered because it doesn't contain the classes of the entries\n",
    "    #test_file_path = 'test.csv'\n",
    "    resources_file_path = 'resources.csv'\n",
    "\n",
    "    # Read data and store in DataFrame\n",
    "    train_data = pd.read_csv(train_file_path, sep=',')\n",
    "    #test_data = pd.read_csv(test_file_path, sep=',')\n",
    "    resources_data = pd.read_csv(resources_file_path, sep=',')\n",
    "    \n",
    "    return train_data, resources_data\n",
    "\n",
    "# splitting the training dataset into training and test, because the official test dataset\n",
    "# doesn't have the entries' classification, requiring validation with Kaggle's website\n",
    "def splitData(train_data, resources_data, training_set_total_aproved, training_set_total_reproved):\n",
    "    \n",
    "    print(\"Total data: \", len(train_data))\n",
    "    print(\"Total aproved: \", train_data[\"project_is_approved\"].sum())\n",
    "    print(\"Total reproved: \", len(train_data) - train_data[\"project_is_approved\"].sum())\n",
    "    print(\"Percent aproved: \", float(train_data[\"project_is_approved\"].sum()) / float(len(train_data)))\n",
    "    print(\"Percent reproved: \", 1.0 - (float(train_data[\"project_is_approved\"].sum()) / float(len(train_data))), \"\\n\")\n",
    "\n",
    "    train = train_data.sample(n=10000,random_state=200)\n",
    "    print(\"Distribution over a random sample of 10000 observations used to get the observations to train the classifier: \",\n",
    "          float(train[\"project_is_approved\"].sum()) / float(len(train[\"project_is_approved\"])))\n",
    "    print(\"Total aproved in that sample: \", train[\"project_is_approved\"].sum(), \"\\n\")\n",
    "    \n",
    "    aproved = train[train[\"project_is_approved\"] == 1][:training_set_total_aproved]\n",
    "    reproved = train[train[\"project_is_approved\"] == 0][:training_set_total_reproved]\n",
    "\n",
    "    training_set = pd.concat([aproved, reproved])\n",
    "    training_set = training_set.sample(frac=1, random_state=200)\n",
    "    test_set = train_data.drop(training_set.index)\n",
    "\n",
    "    print(\"Total training data: \", len(training_set))\n",
    "    print(\"Total aproved: \", training_set[\"project_is_approved\"].sum())\n",
    "    print(\"Total reproved: \", len(training_set) - training_set[\"project_is_approved\"].sum())\n",
    "    print(\"Percent aproved: \", float(training_set[\"project_is_approved\"].sum()) / float(len(training_set)))\n",
    "    print(\"Percent reproved: \", 1.0 - (float(training_set[\"project_is_approved\"].sum()) / float(len(training_set))), \"\\n\")\n",
    "\n",
    "    print(\"Total test data: \", len(test_set))\n",
    "    print(\"Total aproved: \", test_set[\"project_is_approved\"].sum())\n",
    "    print(\"Total reproved: \", len(test_set) - test_set[\"project_is_approved\"].sum())\n",
    "    print(\"Percent aproved: \", float(test_set[\"project_is_approved\"].sum()) / float(len(test_set)))\n",
    "    print(\"Percent reproved: \", 1.0 - (float(test_set[\"project_is_approved\"].sum()) / float(len(test_set))), \"\\n\")\n",
    "\n",
    "    print(\"Training set + test set: \", len(training_set) + len(test_set))\n",
    "\n",
    "    return training_set, test_set\n",
    "\n",
    "\n",
    "def getData(training_set_total_aproved, training_set_total_reproved):\n",
    "    train_data, resources_data = loadData()\n",
    "    training_set, test_set = splitData(train_data, resources_data, training_set_total_aproved, training_set_total_reproved)\n",
    "    \n",
    "    training_df = preprocess(training_set, resources_data)\n",
    "    test_df = preprocess(test_set, resources_data)\n",
    "    \n",
    "    training_input, expected_output, training_combined = convert_to_bits_string(training_df)\n",
    "    test_input, test_expected_output, test_combined = convert_to_bits_string(test_df)\n",
    "    \n",
    "    return training_input, expected_output, training_combined, test_input, test_expected_output, test_combined, training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains using a WiSARD classifier\n",
    "# Using personal implementation, without bleaching\n",
    "def train(training_input, expected_output, tuple_size = 2, bleaching = False):\n",
    "    wann = Wisard(tuple_size, 3546, bleaching)\n",
    "    wann.train(training_input, expected_output)\n",
    "    return wann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluates Guilherme's wisard implementation\n",
    "def evaluate_performance(wann, test_data_combined):\n",
    "    #print(\"Number of observations: \", test_data_combined)\n",
    "    correct_predictions = 0\n",
    "    wrong_predictions = 0\n",
    "    zeros_predicted = 0\n",
    "    ones_predicted = 0\n",
    "    zeros_correct = 0\n",
    "    ones_correct = 0\n",
    "    zeros_wrong = 0\n",
    "    ones_wrong = 0\n",
    "    for combined in test_data_combined:\n",
    "        prediction = wann.predict(combined[0])\n",
    "        prediction = prediction[\"class\"]\n",
    "        \n",
    "        if prediction == \"0\":\n",
    "            #print(\"Prediction: \", prediction[0], combined)\n",
    "            zeros_predicted = zeros_predicted + 1\n",
    "        elif prediction == \"1\":\n",
    "            ones_predicted = ones_predicted + 1\n",
    "        #print(prediction)\n",
    "        expected = combined[1]\n",
    "        #print(prediction, expected)\n",
    "        if prediction == expected:\n",
    "            #print(\"Correct!\")\n",
    "            correct_predictions = correct_predictions + 1\n",
    "            \n",
    "            if prediction == \"0\":\n",
    "                zeros_correct = zeros_correct + 1\n",
    "            elif prediction == \"1\":\n",
    "                ones_correct = ones_correct + 1\n",
    "        else:\n",
    "            wrong_predictions = wrong_predictions + 1\n",
    "            \n",
    "            if prediction == \"0\":\n",
    "                zeros_wrong = zeros_wrong + 1\n",
    "            elif prediction == \"1\":\n",
    "                ones_wrong = ones_wrong + 1\n",
    "    \n",
    "    print(\"Number of observations: \", len(test_data_combined))\n",
    "    print(\"Predicted correctly: \", correct_predictions)\n",
    "    print(\"Predicted wrongly: \", wrong_predictions)\n",
    "    print(\"Predicted zeros: \", zeros_predicted)\n",
    "    print(\"Predicted ones: \", ones_predicted)\n",
    "    print(\"Zeros correct: \", zeros_correct)\n",
    "    print(\"Ones correct: \", ones_correct)\n",
    "    print(\"Zeros wrong: \", zeros_wrong)\n",
    "    print(\"Ones Wrong: \", ones_wrong)\n",
    "    return correct_predictions, [\n",
    "        len(test_data_combined), correct_predictions, wrong_predictions, zeros_predicted, ones_predicted,\n",
    "        zeros_correct, ones_correct, zeros_wrong, ones_wrong\n",
    "    ]\n",
    "\n",
    "#Evaluates Firminos's wisard implementation\n",
    "def evaluate_performance2(w, test_data_combined):\n",
    "    #print(\"Number of observations: \", test_data_combined)\n",
    "    correct_predictions = 0\n",
    "    wrong_predictions = 0\n",
    "    zeros_predicted = 0\n",
    "    ones_predicted = 0\n",
    "    zeros_correct = 0\n",
    "    ones_correct = 0\n",
    "    zeros_wrong = 0\n",
    "    ones_wrong = 0\n",
    "    for combined in test_data_combined:\n",
    "        prediction = w.predict([combined[0]])\n",
    "        if prediction[0] == \"0\":\n",
    "            #print(\"Prediction: \", prediction[0], combined)\n",
    "            zeros_predicted = zeros_predicted + 1\n",
    "        elif prediction[0] == \"1\":\n",
    "            ones_predicted = ones_predicted + 1\n",
    "        #print(prediction)\n",
    "        expected = combined[1]\n",
    "        #print(prediction, expected)\n",
    "        if prediction[0] == expected:\n",
    "            #print(\"Correct!\")\n",
    "            correct_predictions = correct_predictions + 1\n",
    "            \n",
    "            if prediction[0] == \"0\":\n",
    "                zeros_correct = zeros_correct + 1\n",
    "            elif prediction[0] == \"1\":\n",
    "                ones_correct = ones_correct + 1\n",
    "        else:\n",
    "            wrong_predictions = wrong_predictions + 1\n",
    "            \n",
    "            if prediction[0] == \"0\":\n",
    "                zeros_wrong = zeros_wrong + 1\n",
    "            elif prediction[0] == \"1\":\n",
    "                ones_wrong = ones_wrong + 1\n",
    "    \n",
    "    print(\"Number of observations: \", len(test_data_combined))\n",
    "    print(\"Predicted correctly: \", correct_predictions)\n",
    "    print(\"Predicted wrongly: \", wrong_predictions)\n",
    "    print(\"Predicted zeros: \", zeros_predicted)\n",
    "    print(\"Predicted ones: \", ones_predicted)\n",
    "    print(\"Zeros correct: \", zeros_correct)\n",
    "    print(\"Ones correct: \", ones_correct)\n",
    "    print(\"Zeros wrong: \", zeros_wrong)\n",
    "    print(\"Ones Wrong: \", ones_wrong)\n",
    "    return correct_predictions, [\n",
    "        len(test_data_combined), correct_predictions, wrong_predictions, zeros_predicted, ones_predicted,\n",
    "        zeros_correct, ones_correct, zeros_wrong, ones_wrong\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(training_set_distribuitions, tuple_sizes, bleaching_mode = [False]):\n",
    "    output_file = \"insights/results_experiment\" + datetime.now().strftime('%Y%m%d%H%M%S') + \".csv\"\n",
    "    file = open(output_file, \"w\")\n",
    "    file.write(\"data_distribution;tuple_size;bleaching_active;total_training_data;total_correct_training;\" +\n",
    "               \"percent_correct_training;total_approved_training;correctly_approved_training;wrongly_approved_training;\" +\n",
    "               \"percent_approved_correctly_training;total_reproved_training;correctly_reproved_training;\" +\n",
    "               \"wrongly_reproved_training;percent_reproved_correctly_training;total_test_data;total_correct_test;\" +\n",
    "               \"percent_correct_test;total_approved_test;correctly_approved_test;wrongly_approved_test;\" +\n",
    "               \"percent_approved_correctly_test;total_reproved_test;correctly_reproved_test;\" +\n",
    "               \"wrongly_reproved_test;percent_reproved_correctly_test;\\n\"\n",
    "              )\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "    for training_set_distribuition in training_set_distribuitions:\n",
    "        print(\"\\nTraining with a training set distribution of \", \n",
    "              training_set_distribuition[0], training_set_distribuition[1],\n",
    "              \" for approved and repproved, respectively.\\n\")\n",
    "        training_input, expected_output, training_combined, test_input, test_expected_output, test_combined, training_set, test_set = getData(training_set_distribuition[0], training_set_distribuition[1])\n",
    "        \n",
    "        for a_tuple_size in tuple_sizes:\n",
    "            print(\"Training with a tupple of size: \", a_tuple_size)\n",
    "            \n",
    "            for bleaching in bleaching_mode:\n",
    "                print(\"Bleaching is set to: \", bleaching, \"\\n\")\n",
    "\n",
    "                wann = train(training_input, expected_output, a_tuple_size, bleaching)\n",
    "\n",
    "                in_sample_performance, in_sample_additional_info =  evaluate_performance(wann, training_combined)\n",
    "                \n",
    "                # Evaluates Guilherme's wisard implementation\n",
    "                print(\"In-sample performance: \", float(in_sample_performance) / float(len(training_combined)))\n",
    "                print(\"Ones distribution: \", float(training_set[\"project_is_approved\"].sum()) / float(len(training_set[\"project_is_approved\"])))\n",
    "                print(\"Ones: \", training_set[\"project_is_approved\"].sum(), \"Zeros: \", training_set[\"project_is_approved\"].sum() - len(training_set[\"project_is_approved\"]))\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                out_sample_performance, out_sample_additional_info =  evaluate_performance(wann, test_combined)\n",
    "                \n",
    "                print(\"Expected out-sample performance: \", float(out_sample_performance) / float(len(test_combined)))\n",
    "                print(\"Ones distribution: \", float(test_set[\"project_is_approved\"].sum()) / float(len(test_set[\"project_is_approved\"])))\n",
    "                print(\"Ones: \", test_set[\"project_is_approved\"].sum(), \"Zeros: \", (test_set[\"project_is_approved\"].sum() - len(test_set[\"project_is_approved\"])), \"\\n\\n\")\n",
    "                \n",
    "                line = \"\"\n",
    "                line_contents = [\n",
    "                    # training / test\n",
    "                    str(training_set_distribuition[0]) + \"/\" + str(training_set_distribuition[1]) + \";\",\n",
    "                    # tuple size\n",
    "                    str(a_tuple_size) + \";\",\n",
    "                    # bleaching active or not\n",
    "                    str(bleaching) + \";\",\n",
    "                    \n",
    "                    # total traning observations\n",
    "                    str(training_set_distribuition[0] + training_set_distribuition[1]) + \";\",\n",
    "                    # total of correct prediction in the training dataset\n",
    "                    str(in_sample_performance) + \";\",\n",
    "                    # percentage of right answers\n",
    "                    str(float(in_sample_performance) / float(len(training_combined))) + \";\",\n",
    "                    # total approved in the training dataset\n",
    "                    str(training_set[\"project_is_approved\"].sum()) + \";\",\n",
    "                    # total approved correctly predicted in the training dataset\n",
    "                    str(in_sample_additional_info[6]) + \";\",\n",
    "                    # total approved wrongly predicted in the training dataset\n",
    "                    str(in_sample_additional_info[8]) + \";\",\n",
    "                    # percentage of approved projects predicted correctly in the training dataset\n",
    "                    str(float(in_sample_additional_info[6]) / float(training_set[\"project_is_approved\"].sum())) + \";\",\n",
    "                    # total reproved in the training dataset\n",
    "                    str((training_set[\"project_is_approved\"].sum() - len(training_set[\"project_is_approved\"])) * -1) + \";\",\n",
    "                    # total reproved correctly predicted in the training dataset\n",
    "                    str(in_sample_additional_info[5]) + \";\",\n",
    "                    # total reproved wrongly predicted in the training dataset\n",
    "                    str(in_sample_additional_info[7]) + \";\",\n",
    "                    # percentage of reproved projects predicted correctly in the training dataset\n",
    "                    str(float(in_sample_additional_info[5]) / float((training_set[\"project_is_approved\"].sum() - len(training_set[\"project_is_approved\"])) * -1)) + \";\",\n",
    "\n",
    "                    \n",
    "                    # total test observations\n",
    "                    str(len(test_set[\"project_is_approved\"])) + \";\",\n",
    "                    # total of correct prediction in the test dataset\n",
    "                    str(out_sample_performance) + \";\",\n",
    "                    # percentage of right answers\n",
    "                    str(float(out_sample_performance) / float(len(test_combined))) + \";\",\n",
    "                    # total approved in the test dataset\n",
    "                    str(test_set[\"project_is_approved\"].sum()) + \";\",\n",
    "                    # total approved correctly predicted in the test dataset\n",
    "                    str(out_sample_additional_info[6]) + \";\",\n",
    "                    # total approved wrongly predicted in the test dataset\n",
    "                    str(out_sample_additional_info[8]) + \";\",\n",
    "                    # percentage of approved projects predicted correctly in the test dataset\n",
    "                    str(float(out_sample_additional_info[6]) / float(test_set[\"project_is_approved\"].sum())) + \";\",\n",
    "                    # total reproved in the test dataset\n",
    "                    str((test_set[\"project_is_approved\"].sum() - len(test_set[\"project_is_approved\"])) * -1) + \";\",\n",
    "                    # total reproved correctly predicted in the training dataset\n",
    "                    str(out_sample_additional_info[5]) + \";\",\n",
    "                    # total reproved wrongly predicted in the training dataset\n",
    "                    str(out_sample_additional_info[7]) + \";\",\n",
    "                    # percentage of reproved projects predicted correctly in the training dataset\n",
    "                    str(float(out_sample_additional_info[5]) / float((test_set[\"project_is_approved\"].sum() - len(test_set[\"project_is_approved\"])) * -1)) + \";\",\n",
    "                    \n",
    "                    \"\\n\",\n",
    "                    #str() + \";\",\n",
    "                ]\n",
    "\n",
    "                for content in line_contents:\n",
    "                    #print(content)\n",
    "                    line = line + content\n",
    "\n",
    "                print(line)\n",
    "                \n",
    "                file = open(output_file, \"a+\")\n",
    "                file.write(line)\n",
    "                file.close()\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with a training set distribution of  10 10  for approved and repproved, respectively.\n",
      "\n",
      "Total data:  182080\n",
      "Total aproved:  154346\n",
      "Total reproved:  27734\n",
      "Percent aproved:  0.8476823374340949\n",
      "Percent reproved:  0.15231766256590507 \n",
      "\n",
      "Distribution over a random sample of 10000 observations used to get the observations to train the classifier:  0.8492\n",
      "Total aproved in that sample:  8492 \n",
      "\n",
      "Total training data:  20\n",
      "Total aproved:  10\n",
      "Total reproved:  10\n",
      "Percent aproved:  0.5\n",
      "Percent reproved:  0.5 \n",
      "\n",
      "Total test data:  182060\n",
      "Total aproved:  154336\n",
      "Total reproved:  27724\n",
      "Percent aproved:  0.8477205316928486\n",
      "Percent reproved:  0.15227946830715144 \n",
      "\n",
      "Training set + test set:  182080\n",
      "Converting dataframe of shape  (20, 18)  to a list of binary values.\n",
      "Converting dataframe of shape  (182060, 18)  to a list of binary values.\n",
      "Training with a tupple of size:  1\n",
      "Bleaching is set to:  False \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  19\n",
      "Predicted wrongly:  1\n",
      "Predicted zeros:  9\n",
      "Predicted ones:  11\n",
      "Zeros correct:  9\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  1\n",
      "In-sample performance:  0.95\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  101591\n",
      "Predicted wrongly:  80469\n",
      "Predicted zeros:  76971\n",
      "Predicted ones:  105089\n",
      "Zeros correct:  12113\n",
      "Ones correct:  89478\n",
      "Zeros wrong:  64858\n",
      "Ones Wrong:  15611\n",
      "Expected out-sample performance:  0.5580083488959684\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;1;False;20;19;0.95;10;10;1;1.0;10;9;0;0.9;182060;101591;0.5580083488959684;154336;89478;15611;0.5797610408459465;27724;12113;64858;0.43691386524311066;\n",
      "\n",
      "Bleaching is set to:  True \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  85367\n",
      "Predicted wrongly:  96693\n",
      "Predicted zeros:  100583\n",
      "Predicted ones:  81477\n",
      "Zeros correct:  15807\n",
      "Ones correct:  69560\n",
      "Zeros wrong:  84776\n",
      "Ones Wrong:  11917\n",
      "Expected out-sample performance:  0.4688948698231352\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;1;True;20;20;1.0;10;10;0;1.0;10;10;0;1.0;182060;85367;0.4688948698231352;154336;69560;11917;0.45070495542193656;27724;15807;84776;0.5701558216707546;\n",
      "\n",
      "Training with a tupple of size:  2\n",
      "Bleaching is set to:  False \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  19\n",
      "Predicted wrongly:  1\n",
      "Predicted zeros:  9\n",
      "Predicted ones:  11\n",
      "Zeros correct:  9\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  1\n",
      "In-sample performance:  0.95\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  103180\n",
      "Predicted wrongly:  78880\n",
      "Predicted zeros:  75508\n",
      "Predicted ones:  106552\n",
      "Zeros correct:  12176\n",
      "Ones correct:  91004\n",
      "Zeros wrong:  63332\n",
      "Ones Wrong:  15548\n",
      "Expected out-sample performance:  0.5667362407997364\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;2;False;20;19;0.95;10;10;1;1.0;10;9;0;0.9;182060;103180;0.5667362407997364;154336;91004;15548;0.5896485589881816;27724;12176;63332;0.43918626460828164;\n",
      "\n",
      "Bleaching is set to:  True \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  91340\n",
      "Predicted wrongly:  90720\n",
      "Predicted zeros:  92466\n",
      "Predicted ones:  89594\n",
      "Zeros correct:  14735\n",
      "Ones correct:  76605\n",
      "Zeros wrong:  77731\n",
      "Ones Wrong:  12989\n",
      "Expected out-sample performance:  0.5017027353619686\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;2;True;20;20;1.0;10;10;0;1.0;10;10;0;1.0;182060;91340;0.5017027353619686;154336;76605;12989;0.4963521148662658;27724;14735;77731;0.5314889626316549;\n",
      "\n",
      "Training with a tupple of size:  4\n",
      "Bleaching is set to:  False \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  19\n",
      "Predicted wrongly:  1\n",
      "Predicted zeros:  9\n",
      "Predicted ones:  11\n",
      "Zeros correct:  9\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  1\n",
      "In-sample performance:  0.95\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  115294\n",
      "Predicted wrongly:  66766\n",
      "Predicted zeros:  56762\n",
      "Predicted ones:  125298\n",
      "Zeros correct:  8860\n",
      "Ones correct:  106434\n",
      "Zeros wrong:  47902\n",
      "Ones Wrong:  18864\n",
      "Expected out-sample performance:  0.6332747445896957\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;4;False;20;19;0.95;10;10;1;1.0;10;9;0;0.9;182060;115294;0.6332747445896957;154336;106434;18864;0.6896252332573087;27724;8860;47902;0.3195787043716635;\n",
      "\n",
      "Bleaching is set to:  True \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  101985\n",
      "Predicted wrongly:  80075\n",
      "Predicted zeros:  75935\n",
      "Predicted ones:  106125\n",
      "Zeros correct:  11792\n",
      "Ones correct:  90193\n",
      "Zeros wrong:  64143\n",
      "Ones Wrong:  15932\n",
      "Expected out-sample performance:  0.5601724706140833\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;4;True;20;20;1.0;10;10;0;1.0;10;10;0;1.0;182060;101985;0.5601724706140833;154336;90193;15932;0.584393790172092;27724;11792;64143;0.42533544943009666;\n",
      "\n",
      "Training with a tupple of size:  5\n",
      "Bleaching is set to:  False \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  90156\n",
      "Predicted wrongly:  91904\n",
      "Predicted zeros:  92772\n",
      "Predicted ones:  89288\n",
      "Zeros correct:  14296\n",
      "Ones correct:  75860\n",
      "Zeros wrong:  78476\n",
      "Ones Wrong:  13428\n",
      "Expected out-sample performance:  0.4951993848181918\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;5;False;20;20;1.0;10;10;0;1.0;10;10;0;1.0;182060;90156;0.4951993848181918;154336;75860;13428;0.49152498444951276;27724;14296;78476;0.5156543067378445;\n",
      "\n",
      "Bleaching is set to:  True \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  77658\n",
      "Predicted wrongly:  104402\n",
      "Predicted zeros:  111266\n",
      "Predicted ones:  70794\n",
      "Zeros correct:  17294\n",
      "Ones correct:  60364\n",
      "Zeros wrong:  93972\n",
      "Ones Wrong:  10430\n",
      "Expected out-sample performance:  0.4265516862572778\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;5;True;20;20;1.0;10;10;0;1.0;10;10;0;1.0;182060;77658;0.4265516862572778;154336;60364;10430;0.39112067178104915;27724;17294;93972;0.6237916606550281;\n",
      "\n",
      "Training with a tupple of size:  7\n",
      "Bleaching is set to:  False \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:  182060\n",
      "Predicted correctly:  94511\n",
      "Predicted wrongly:  87549\n",
      "Predicted zeros:  86819\n",
      "Predicted ones:  95241\n",
      "Zeros correct:  13497\n",
      "Ones correct:  81014\n",
      "Zeros wrong:  73322\n",
      "Ones Wrong:  14227\n",
      "Expected out-sample performance:  0.5191200703064923\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;7;False;20;20;1.0;10;10;0;1.0;10;10;0;1.0;182060;94511;0.5191200703064923;154336;81014;14227;0.5249196558158822;27724;13497;73322;0.48683451161448565;\n",
      "\n",
      "Bleaching is set to:  True \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  80470\n",
      "Predicted wrongly:  101590\n",
      "Predicted zeros:  106730\n",
      "Predicted ones:  75330\n",
      "Zeros correct:  16432\n",
      "Ones correct:  64038\n",
      "Zeros wrong:  90298\n",
      "Ones Wrong:  11292\n",
      "Expected out-sample performance:  0.44199714379874766\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;7;True;20;20;1.0;10;10;0;1.0;10;10;0;1.0;182060;80470;0.44199714379874766;154336;64038;11292;0.4149258760107817;27724;16432;90298;0.5926994661664984;\n",
      "\n",
      "Training with a tupple of size:  10\n",
      "Bleaching is set to:  False \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  104812\n",
      "Predicted wrongly:  77248\n",
      "Predicted zeros:  71766\n",
      "Predicted ones:  110294\n",
      "Zeros correct:  11121\n",
      "Ones correct:  93691\n",
      "Zeros wrong:  60645\n",
      "Ones Wrong:  16603\n",
      "Expected out-sample performance:  0.5757003185762936\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;10;False;20;20;1.0;10;10;0;1.0;10;10;0;1.0;182060;104812;0.5757003185762936;154336;93691;16603;0.6070586253369272;27724;11121;60645;0.40113259269946616;\n",
      "\n",
      "Bleaching is set to:  True \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n",
      "Number of observations:  182060\n",
      "Predicted correctly:  90539\n",
      "Predicted wrongly:  91521\n",
      "Predicted zeros:  92433\n",
      "Predicted ones:  89627\n",
      "Zeros correct:  14318\n",
      "Ones correct:  76221\n",
      "Zeros wrong:  78115\n",
      "Ones Wrong:  13406\n",
      "Expected out-sample performance:  0.4973030868944304\n",
      "Ones distribution:  0.8477205316928486\n",
      "Ones:  154336 Zeros:  -27724 \n",
      "\n",
      "\n",
      "10/10;10;True;20;20;1.0;10;10;0;1.0;10;10;0;1.0;182060;90539;0.4973030868944304;154336;76221;13406;0.4938640369064897;27724;14318;78115;0.5164478430240946;\n",
      "\n",
      "Training with a tupple of size:  20\n",
      "Bleaching is set to:  False \n",
      "\n",
      "Number of classes being trained: 2\n",
      "dict_keys(['1', '0'])\n",
      "Number of training samples for class 1: 10\n",
      "Number of training samples for class 0: 10\n",
      "Number of observations:  20\n",
      "Predicted correctly:  20\n",
      "Predicted wrongly:  0\n",
      "Predicted zeros:  10\n",
      "Predicted ones:  10\n",
      "Zeros correct:  10\n",
      "Ones correct:  10\n",
      "Zeros wrong:  0\n",
      "Ones Wrong:  0\n",
      "In-sample performance:  1.0\n",
      "Ones distribution:  0.5\n",
      "Ones:  10 Zeros:  -10\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'input_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-066b15d37403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraining_set_distribuitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m86\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set_distribuitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-e8c17732b739>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(training_set_distribuitions, tuple_sizes, bleaching_mode)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mout_sample_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_sample_additional_info\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mevaluate_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwann\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected out-sample performance: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_sample_performance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6d4b4595dafa>\u001b[0m in \u001b[0;36mevaluate_performance\u001b[0;34m(wann, test_data_combined)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mones_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcombined\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data_combined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/dc_comp/Wisard.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, rawinput)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# If the method ends with more than one class as possible, it just returns the first one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredicted_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"discriminator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredicted_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeactivate_bleaching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'input_class'"
     ]
    }
   ],
   "source": [
    "tuple_sizes = [1, 2, 4, 5, 7, 10, 20, 25, 30, 50, 100]\n",
    "#tuple_sizes = [50, 100]\n",
    "training_set_distribuitions = [[10, 10], [20, 20], [30, 30], [50, 50], [75, 75], [86, 14]]\n",
    "\n",
    "experiment(training_set_distribuitions, tuple_sizes, [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
